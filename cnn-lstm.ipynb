{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6946700,"sourceType":"datasetVersion","datasetId":3989601},{"sourceId":7005884,"sourceType":"datasetVersion","datasetId":4027597}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport librosa\nimport librosa.display\nimport matplotlib.pyplot as plt\nimport IPython.display as ipd\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom datetime import datetime\n\n# Load your data here\ndata_path = '/kaggle/input/pig-disease-f/data 2/Train'\nmetadata = pd.read_csv('//kaggle/input/pig-data/data.csv')\n\nclass_names = {\n    1: 'Pneumonia',\n    2: 'PRRS',\n    3: 'Swine Fever'\n    # Add more class IDs and their corresponding names as needed\n}\n\nmetadata['class_name'] = metadata['classID'].map(class_names)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-17T00:13:27.681936Z","iopub.execute_input":"2023-12-17T00:13:27.682211Z","iopub.status.idle":"2023-12-17T00:13:41.167915Z","shell.execute_reply.started":"2023-12-17T00:13:27.682185Z","shell.execute_reply":"2023-12-17T00:13:41.167008Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Assuming that your audio files are organized in folders named after their classes\nclass_folders = ['Pnemonia', 'prrs', 'swine_fever']\naudio_data = []\nlabels = []\n\nfor folder in class_folders:\n    folder_path = os.path.join(data_path, folder)\n    for filename in os.listdir(folder_path):\n        if filename.endswith('.wav'):\n            audio_path = os.path.join(folder_path, filename)\n            audio, sr = librosa.load(audio_path, sr=None)\n            mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n            audio_data.append(mfccs)\n            labels.append(folder)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T00:14:34.394950Z","iopub.execute_input":"2023-12-17T00:14:34.396142Z","iopub.status.idle":"2023-12-17T00:15:08.414400Z","shell.execute_reply.started":"2023-12-17T00:14:34.396100Z","shell.execute_reply":"2023-12-17T00:15:08.412978Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Padding MFCCs to ensure uniformity in feature dimensions\nmax_length = max([mfcc.shape[1] for mfcc in audio_data])\npadded_mfccs = [np.pad(mfcc, pad_width=((0, 0), (0, max_length - mfcc.shape[1])), mode='constant') for mfcc in audio_data]\n\n# Converting to NumPy arrays\nX = np.array(padded_mfccs)\ny = np.array(labels)\n\n# Reshape for LSTM input\nX = X.reshape(X.shape[0], X.shape[2], X.shape[1]) # Reshaping to (samples, timesteps, features)\n\n# Label encoding\nlabelencoder = LabelEncoder()\ny = to_categorical(labelencoder.fit_transform(y))\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T00:15:53.798188Z","iopub.execute_input":"2023-12-17T00:15:53.799116Z","iopub.status.idle":"2023-12-17T00:15:53.970606Z","shell.execute_reply.started":"2023-12-17T00:15:53.799075Z","shell.execute_reply":"2023-12-17T00:15:53.969534Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\nmodel.add(Dropout(0.5))\nmodel.add(LSTM(64))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(y_train.shape[1], activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T00:15:58.203245Z","iopub.execute_input":"2023-12-17T00:15:58.204127Z","iopub.status.idle":"2023-12-17T00:16:03.055013Z","shell.execute_reply.started":"2023-12-17T00:15:58.204088Z","shell.execute_reply":"2023-12-17T00:16:03.054142Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n lstm (LSTM)                 (None, 390, 128)          86528     \n                                                                 \n dropout (Dropout)           (None, 390, 128)          0         \n                                                                 \n lstm_1 (LSTM)               (None, 64)                49408     \n                                                                 \n dropout_1 (Dropout)         (None, 64)                0         \n                                                                 \n dense (Dense)               (None, 3)                 195       \n                                                                 \n=================================================================\nTotal params: 136131 (531.76 KB)\nTrainable params: 136131 (531.76 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"num_epochs = 10\nnum_batch_size = 32\ncheckpointer = ModelCheckpoint(filepath='./audio_classification_lstm.hdf5', verbose=1, save_best_only=True)\n\nstart = datetime.now()\nmodel.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\nprint(\"Training completed in time: \", datetime.now() - start)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T00:16:17.176331Z","iopub.execute_input":"2023-12-17T00:16:17.176700Z","iopub.status.idle":"2023-12-17T00:16:34.399891Z","shell.execute_reply.started":"2023-12-17T00:16:17.176669Z","shell.execute_reply":"2023-12-17T00:16:34.399030Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Epoch 1/10\n24/26 [==========================>...] - ETA: 0s - loss: 0.8050 - accuracy: 0.7083\nEpoch 1: val_loss improved from inf to 0.52609, saving model to ./audio_classification_lstm.hdf5\n26/26 [==============================] - 11s 69ms/step - loss: 0.7849 - accuracy: 0.7197 - val_loss: 0.5261 - val_accuracy: 0.8155\nEpoch 2/10\n 4/26 [===>..........................] - ETA: 0s - loss: 0.5811 - accuracy: 0.8047","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"25/26 [===========================>..] - ETA: 0s - loss: 0.5547 - accuracy: 0.8087\nEpoch 2: val_loss improved from 0.52609 to 0.44545, saving model to ./audio_classification_lstm.hdf5\n26/26 [==============================] - 1s 28ms/step - loss: 0.5554 - accuracy: 0.8083 - val_loss: 0.4455 - val_accuracy: 0.8301\nEpoch 3/10\n25/26 [===========================>..] - ETA: 0s - loss: 0.4416 - accuracy: 0.8462\nEpoch 3: val_loss improved from 0.44545 to 0.41763, saving model to ./audio_classification_lstm.hdf5\n26/26 [==============================] - 1s 28ms/step - loss: 0.4459 - accuracy: 0.8459 - val_loss: 0.4176 - val_accuracy: 0.8641\nEpoch 4/10\n24/26 [==========================>...] - ETA: 0s - loss: 0.3497 - accuracy: 0.8854\nEpoch 4: val_loss improved from 0.41763 to 0.37296, saving model to ./audio_classification_lstm.hdf5\n26/26 [==============================] - 1s 28ms/step - loss: 0.3493 - accuracy: 0.8859 - val_loss: 0.3730 - val_accuracy: 0.8495\nEpoch 5/10\n25/26 [===========================>..] - ETA: 0s - loss: 0.2531 - accuracy: 0.9250\nEpoch 5: val_loss did not improve from 0.37296\n26/26 [==============================] - 1s 27ms/step - loss: 0.2562 - accuracy: 0.9248 - val_loss: 0.4436 - val_accuracy: 0.8495\nEpoch 6/10\n25/26 [===========================>..] - ETA: 0s - loss: 0.2214 - accuracy: 0.9337\nEpoch 6: val_loss did not improve from 0.37296\n26/26 [==============================] - 1s 27ms/step - loss: 0.2215 - accuracy: 0.9333 - val_loss: 0.4533 - val_accuracy: 0.8592\nEpoch 7/10\n25/26 [===========================>..] - ETA: 0s - loss: 0.1834 - accuracy: 0.9388\nEpoch 7: val_loss did not improve from 0.37296\n26/26 [==============================] - 1s 27ms/step - loss: 0.1877 - accuracy: 0.9381 - val_loss: 0.5320 - val_accuracy: 0.8204\nEpoch 8/10\n25/26 [===========================>..] - ETA: 0s - loss: 0.1378 - accuracy: 0.9563\nEpoch 8: val_loss did not improve from 0.37296\n26/26 [==============================] - 1s 27ms/step - loss: 0.1380 - accuracy: 0.9563 - val_loss: 0.6543 - val_accuracy: 0.8058\nEpoch 9/10\n25/26 [===========================>..] - ETA: 0s - loss: 0.1206 - accuracy: 0.9550\nEpoch 9: val_loss did not improve from 0.37296\n26/26 [==============================] - 1s 27ms/step - loss: 0.1196 - accuracy: 0.9563 - val_loss: 0.6168 - val_accuracy: 0.8058\nEpoch 10/10\n25/26 [===========================>..] - ETA: 0s - loss: 0.0737 - accuracy: 0.9812\nEpoch 10: val_loss did not improve from 0.37296\n26/26 [==============================] - 1s 28ms/step - loss: 0.0724 - accuracy: 0.9818 - val_loss: 0.6603 - val_accuracy: 0.8155\nTraining completed in time:  0:00:17.217603\n","output_type":"stream"}]},{"cell_type":"code","source":"test_accuracy = model.evaluate(X_test, y_test, verbose=0)\nprint(f'Test accuracy: {test_accuracy[1]}')","metadata":{"execution":{"iopub.status.busy":"2023-12-17T00:16:52.352541Z","iopub.execute_input":"2023-12-17T00:16:52.353388Z","iopub.status.idle":"2023-12-17T00:16:52.609300Z","shell.execute_reply.started":"2023-12-17T00:16:52.353351Z","shell.execute_reply":"2023-12-17T00:16:52.608291Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Test accuracy: 0.8155339956283569\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}